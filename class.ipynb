{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9db1d32d-08c0-4232-9537-4383bdacfb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "17/17 [==============================] - 8s 400ms/step - loss: 80.7561 - accuracy: 0.3708 - val_loss: 1.0539 - val_accuracy: 0.5515\n",
      "Epoch 2/4\n",
      "17/17 [==============================] - 7s 384ms/step - loss: 0.4096 - accuracy: 0.8727 - val_loss: 0.0803 - val_accuracy: 0.9706\n",
      "Epoch 3/4\n",
      "17/17 [==============================] - 7s 405ms/step - loss: 0.1081 - accuracy: 0.9594 - val_loss: 0.0655 - val_accuracy: 0.9853\n",
      "Epoch 4/4\n",
      "17/17 [==============================] - 7s 404ms/step - loss: 0.0548 - accuracy: 0.9815 - val_loss: 0.0891 - val_accuracy: 0.9853\n",
      "5/5 [==============================] - 1s 94ms/step - loss: 0.0891 - accuracy: 0.9853\n",
      "Test accuracy: 0.9852941036224365\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "# import os\n",
    "# import librosa\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# \n",
    "# class VoiceClassifier:\n",
    "#     def __init__(self, data_dir='dataset', test_size=0.2, desired_shape=(128, 128), sr=22050, hop_length=512, n_mels=128):\n",
    "#         self.data_dir = data_dir\n",
    "#         self.test_size = test_size\n",
    "#         self.desired_shape = desired_shape\n",
    "#         self.sr = sr\n",
    "#         self.hop_length = hop_length\n",
    "#         self.n_mels = n_mels\n",
    "#         self.labels = {}\n",
    "#         self.model = None\n",
    "#         self.input_shape = None\n",
    "\n",
    "#     def create_model(self, input_shape, num_classes):\n",
    "#         model = models.Sequential([\n",
    "#             layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "#             layers.MaxPooling2D((2, 2)),\n",
    "#             layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#             layers.MaxPooling2D((2, 2)),\n",
    "#             layers.Flatten(),\n",
    "#             layers.Dense(64, activation='relu'),\n",
    "#             layers.Dense(num_classes, activation='softmax')\n",
    "#         ])\n",
    "#         return model\n",
    "\n",
    "#     def preprocess_data(self):\n",
    "#         X = []\n",
    "#         y = []\n",
    "#         for i, label in enumerate(os.listdir(self.data_dir)):\n",
    "#             label_dir = os.path.join(self.data_dir, label)\n",
    "#             self.labels[i] = label\n",
    "#             for file in os.listdir(label_dir):\n",
    "#                 file_path = os.path.join(label_dir, file)\n",
    "#                 y_, sr = librosa.load(file_path, sr=self.sr)\n",
    "#                 n_fft = min(2048, len(y_))\n",
    "#                 hop_length = n_fft // 4\n",
    "#                 spectrogram = librosa.feature.melspectrogram(y=y_, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=self.n_mels)\n",
    "#                 spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "#                 pad_width = self.desired_shape[1] - spectrogram.shape[1]\n",
    "#                 if pad_width > 0:\n",
    "#                     spectrogram = np.pad(spectrogram, ((0, 0), (0, pad_width)), mode='constant')\n",
    "#                 else:\n",
    "#                     spectrogram = spectrogram[:, :self.desired_shape[1]]\n",
    "#                 X.append(spectrogram)\n",
    "#                 y.append(i)\n",
    "    \n",
    "#         X = np.array(X)\n",
    "#         y = np.array(y)\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.test_size, random_state=42)\n",
    "#         self.input_shape = X_train.shape[1:]\n",
    "#         # Add batch size dimension\n",
    "#         X_train = np.expand_dims(X_train, axis=3)  # or -1\n",
    "#         X_test = np.expand_dims(X_test, axis=3)    # or -1\n",
    "#         return X_train, X_test, y_train, y_test\n",
    "\n",
    "#     def train_model(self, epochs=4, batch_size=32):\n",
    "#         num_classes = len(self.labels)\n",
    "#         X_train, X_test, y_train, y_test = self.preprocess_data()\n",
    "#         self.model = self.create_model(self.input_shape, num_classes)\n",
    "#         self.model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#         self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n",
    "#         test_loss, test_acc = self.model.evaluate(X_test, y_test)\n",
    "#         print('Test accuracy:', test_acc)\n",
    "\n",
    "#     def preprocess_audio(self, audio_file):\n",
    "#         y_, sr = librosa.load(audio_file)\n",
    "#         spectrogram = librosa.feature.melspectrogram(y=y_, sr=sr)\n",
    "#         spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "#         current_shape = spectrogram.shape\n",
    "#         if current_shape[1] > self.desired_shape[1]:\n",
    "#             spectrogram = spectrogram[:, :self.desired_shape[1]]\n",
    "#         elif current_shape[1] < self.desired_shape[1]:\n",
    "#             pad_width = self.desired_shape[1] - current_shape[1]\n",
    "#             spectrogram = np.pad(spectrogram, ((0, 0), (0, pad_width)), mode='constant')\n",
    "#         if current_shape[0] != self.desired_shape[0]:\n",
    "#             spectrogram = librosa.util.fix_length(spectrogram, self.desired_shape[0], axis=0)\n",
    "#         spectrogram = np.expand_dims(spectrogram, axis=-1)\n",
    "#         return spectrogram\n",
    "\n",
    "#     def predict_audio(self, audio_file):\n",
    "#         if not self.model:\n",
    "#             print(\"Error: Model not trained. Please train the model first.\")\n",
    "#             return\n",
    "#         preprocessed_audio = self.preprocess_audio(audio_file)\n",
    "#         predictions = self.model.predict(np.expand_dims(preprocessed_audio, axis=0))\n",
    "#         predicted_class_index = np.argmax(predictions)\n",
    "#         predicted_class = self.labels[predicted_class_index]\n",
    "#         print(\"Predicted class:\", predicted_class)\n",
    "\n",
    "# # Usage example\n",
    "# if __name__ == \"__main__\":\n",
    "#     voice_classifier = VoiceClassifier()\n",
    "#     voice_classifier.train_model()\n",
    "#     audio_file = 'woman_talking_cut.wav'\n",
    "#     voice_classifier.predict_audio(audio_file)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import os\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# class VoiceClassifier:\n",
    "#     def __init__(self, data_dir='dataset', test_size=0.2, desired_shape=(128, 128), sr=22050, hop_length=512, n_mels=128):\n",
    "#         self.data_dir = data_dir\n",
    "#         self.test_size = test_size\n",
    "#         self.desired_shape = desired_shape\n",
    "#         self.sr = sr\n",
    "#         self.hop_length = hop_length\n",
    "#         self.n_mels = n_mels\n",
    "#         self.labels = {}\n",
    "#         self.model = None\n",
    "#         # self.X_train, self.X_test, self.y_train, self.y_test, self.labels = self.preprocess_data()\n",
    "#         # self.num_classes = len(self.labels)\n",
    "#         # self.input_shape = self.X_train.shape[1:]\n",
    "\n",
    "#     def create_model(self, input_shape, num_classes): #, input_shape, num_classes\n",
    "#         model = models.Sequential([\n",
    "#             layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "#             layers.MaxPooling2D((2, 2)),\n",
    "#             layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#             layers.MaxPooling2D((2, 2)),\n",
    "#             layers.Flatten(),\n",
    "#             layers.Dense(64, activation='relu'),\n",
    "#             layers.Dense(num_classes, activation='softmax')\n",
    "#         ])\n",
    "#         # model.summary()\n",
    "#         # model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#         return model\n",
    "\n",
    "#     def preprocess_data(self):\n",
    "#         X = []\n",
    "#         y = []\n",
    "#         for i, label in enumerate(os.listdir(self.data_dir)):\n",
    "#             label_dir = os.path.join(self.data_dir, label)\n",
    "#             self.labels[i] = label\n",
    "#             for file in os.listdir(label_dir):\n",
    "#                 file_path = os.path.join(label_dir, file)\n",
    "#                 y_, sr = librosa.load(file_path, sr=self.sr)\n",
    "#                 n_fft = min(2048, len(y_))\n",
    "#                 hop_length = n_fft // 4\n",
    "#                 spectrogram = librosa.feature.melspectrogram(y=y_, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=self.n_mels)\n",
    "#                 spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "#                 pad_width = self.desired_shape[1] - spectrogram.shape[1]\n",
    "#                 if pad_width > 0:\n",
    "#                     spectrogram = np.pad(spectrogram, ((0, 0), (0, pad_width)), mode='constant')\n",
    "#                 else:\n",
    "#                     spectrogram = spectrogram[:, :self.desired_shape[1]]\n",
    "#                 X.append(spectrogram)\n",
    "#                 y.append(i)\n",
    "    \n",
    "#         X = np.array(X)\n",
    "#         y = np.array(y)\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.test_size, random_state=42)\n",
    "#         input_shape = X_train.shape[1:]\n",
    "#         X_train = np.expand_dims(X_train, axis=-1)\n",
    "#         X_test = np.expand_dims(X_test, axis=-1)\n",
    "#         return X_train, X_test, y_train, y_test, input_shape\n",
    "\n",
    "#     def train_model(self, epochs=4, batch_size=32):\n",
    "#         X_train, X_test, y_train, y_test, labels = self.preprocess_data()\n",
    "#         input_shape = X_train.shape[1:]\n",
    "#         num_classes = len(labels)\n",
    "#         self.model = self.create_model(input_shape, num_classes)\n",
    "#         self.model.summary()\n",
    "#         self.model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#         self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n",
    "#         test_loss, test_acc = self.model.evaluate(X_test, y_test)\n",
    "#         print('Test accuracy:', test_acc)\n",
    "\n",
    "#     def preprocess_audio(self, audio_file):\n",
    "#         y_, sr = librosa.load(audio_file)\n",
    "#         spectrogram = librosa.feature.melspectrogram(y=y_, sr=sr)\n",
    "#         spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "#         current_shape = spectrogram.shape\n",
    "#         if current_shape[1] > self.desired_shape[1]:\n",
    "#             spectrogram = spectrogram[:, :self.desired_shape[1]]\n",
    "#         elif current_shape[1] < self.desired_shape[1]:\n",
    "#             pad_width = self.desired_shape[1] - current_shape[1]\n",
    "#             spectrogram = np.pad(spectrogram, ((0, 0), (0, pad_width)), mode='constant')\n",
    "#         if current_shape[0] != self.desired_shape[0]:\n",
    "#             spectrogram = librosa.util.fix_length(spectrogram, self.desired_shape[0], axis=0)\n",
    "#         spectrogram = np.expand_dims(spectrogram, axis=-1)\n",
    "#         return spectrogram\n",
    "\n",
    "#     def predict_audio(self, audio_file):\n",
    "#         if not self.model:\n",
    "#             print(\"Error: Model not trained. Please train the model first.\")\n",
    "#             return\n",
    "#         preprocessed_audio = self.preprocess_audio(audio_file)\n",
    "#         predictions = self.model.predict(np.expand_dims(preprocessed_audio, axis=0))\n",
    "#         predicted_class_index = np.argmax(predictions)\n",
    "#         predicted_class = self.labels[predicted_class_index]\n",
    "#         print(\"Predicted class:\", predicted_class)\n",
    "\n",
    "# # Usage example\n",
    "# if __name__ == \"__main__\":\n",
    "#     voice_classifier = VoiceClassifier(data_dir='dataset')\n",
    "#     # voice_classifier.create_model()\n",
    "#     voice_classifier.train_model()\n",
    "#     audio_file = 'woman_talking_cut.wav'\n",
    "#     voice_classifier.predict_audio(audio_file)\n",
    "\n",
    "class VoiceClassifier:\n",
    "    # @tf.function(reduce_retracing=True)\n",
    "    def __init__(self, data_dir='dataset', test_size=0.2, desired_shape=(128, 128), sr=22050, hop_length=512, n_mels=128):\n",
    "        self.data_dir = data_dir\n",
    "        self.test_size = test_size\n",
    "        self.desired_shape = desired_shape\n",
    "        self.sr = sr\n",
    "        self.hop_length = hop_length\n",
    "        self.n_mels = n_mels\n",
    "        self.labels = {}\n",
    "        self.model = None\n",
    "\n",
    "    def create_model(self, input_shape, num_classes):\n",
    "        model = models.Sequential([\n",
    "            layers.Reshape((input_shape[0], input_shape[1], 1), input_shape=input_shape),  # Add a channel dimension\n",
    "            layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        return model\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        X = []\n",
    "        y = []\n",
    "        for i, label in enumerate(os.listdir(self.data_dir)):\n",
    "            label_dir = os.path.join(self.data_dir, label)\n",
    "            self.labels[i] = label\n",
    "            for file in os.listdir(label_dir):\n",
    "                file_path = os.path.join(label_dir, file)\n",
    "                y_, sr = librosa.load(file_path, sr=self.sr)\n",
    "                n_fft = min(2048, len(y_))\n",
    "                hop_length = n_fft // 4\n",
    "                spectrogram = librosa.feature.melspectrogram(y=y_, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=self.n_mels)\n",
    "                spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "                pad_width = self.desired_shape[1] - spectrogram.shape[1]\n",
    "                if pad_width > 0:\n",
    "                    spectrogram = np.pad(spectrogram, ((0, 0), (0, pad_width)), mode='constant')\n",
    "                else:\n",
    "                    spectrogram = spectrogram[:, :self.desired_shape[1]]\n",
    "                X.append(spectrogram)\n",
    "                y.append(i)\n",
    "            \n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.test_size, random_state=42)\n",
    "        input_shape = X_train.shape[1:]\n",
    "        num_classes = len(self.labels)\n",
    "        y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "        y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "        return X_train, X_test, y_train, y_test, input_shape, num_classes\n",
    "\n",
    "    def train_model(self, epochs=4, batch_size=32):\n",
    "        X_train, X_test, y_train, y_test, input_shape, num_classes = self.preprocess_data()\n",
    "        self.model = self.create_model(input_shape, num_classes)\n",
    "        self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n",
    "        test_loss, test_acc = self.model.evaluate(X_test, y_test)\n",
    "        print('Test accuracy:', test_acc)\n",
    "\n",
    "    def preprocess_audio(self, audio_file):\n",
    "        y_, sr = librosa.load(audio_file)\n",
    "        spectrogram = librosa.feature.melspectrogram(y=y_, sr=sr)\n",
    "        spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "        current_shape = spectrogram.shape\n",
    "        if current_shape[1] > self.desired_shape[1]:\n",
    "            spectrogram = spectrogram[:, :self.desired_shape[1]]\n",
    "        elif current_shape[1] < self.desired_shape[1]:\n",
    "            pad_width = self.desired_shape[1] - current_shape[1]\n",
    "            spectrogram = np.pad(spectrogram, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        if current_shape[0] != self.desired_shape[0]:\n",
    "            spectrogram = librosa.util.fix_length(spectrogram, self.desired_shape[0], axis=0)\n",
    "        spectrogram = np.expand_dims(spectrogram, axis=-1)\n",
    "        return spectrogram\n",
    "\n",
    "    # def predict_audio(self, audio_file):\n",
    "    #     if not self.model:\n",
    "    #         print(\"Error: Model not trained. Please train the model first.\")\n",
    "    #         return\n",
    "    #     preprocessed_audio = self.preprocess_audio(audio_file)\n",
    "    #     predictions = self.model.predict(np.expand_dims(preprocessed_audio, axis=0))\n",
    "    #     predicted_class_index = np.argmax(predictions)\n",
    "    #     predicted_class = self.labels[predicted_class_index]\n",
    "    #     print(\"Predicted class:\", predicted_class)\n",
    "\n",
    "    def predict_audio(self, audio_file):\n",
    "        if not self.model:\n",
    "            print(\"Error: Model not trained. Please train the model first.\")\n",
    "            return\n",
    "        preprocessed_audio = self.preprocess_audio(audio_file)\n",
    "        predictions = self.model.predict(np.expand_dims(preprocessed_audio, axis=0))\n",
    "        predicted_class_index = np.argmax(predictions)\n",
    "        print('Predicted Class Index: ', predicted_class_index)\n",
    "        print('Labels: ', self.labels)\n",
    "        # Check if predicted class index exists in self.labels\n",
    "        predicted_class = self.labels[predicted_class_index]\n",
    "        print(\"Predicted class:\", predicted_class)\n",
    "\n",
    "    def save_model(self, model_path, labels_path):\n",
    "        self.model.save(model_path)\n",
    "        with open(labels_path, 'w') as f:\n",
    "            json.dump(self.labels, f)\n",
    "\n",
    "    def load_model(self, model_path, labels_path):\n",
    "        self.model = load_model(model_path)\n",
    "        with open(labels_path, 'r') as f:\n",
    "            labels_dict = json.load(f)\n",
    "            self.labels = list(labels_dict.values())\n",
    "\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    voice_classifier = VoiceClassifier(data_dir='dataset')\n",
    "    voice_classifier.train_model()\n",
    "    # audio_file = 'tenor_pavarotti.wav'\n",
    "    # voice_classifier.predict_audio(audio_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fcc0a63f-7afe-40f6-b70b-d6d1ec180dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n",
      "Predicted Class Index:  3\n",
      "Labels:  {0: 'alto', 1: 'bass', 2: 'soprano', 3: 'tenor'}\n",
      "Predicted class: tenor\n"
     ]
    }
   ],
   "source": [
    "    audio_file = 'tenor_pavarotti.wav'\n",
    "    voice_classifier.predict_audio(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "277f4d3f-140a-4f62-af99-53669864c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "    voice_classifier.model.save('model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8f365580-0718-45a3-85e5-8e4e3178d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib, json\n",
    "filename = 'model.sav'\n",
    "joblib.dump(voice_classifier.model, filename)\n",
    "voice_classifier.save_model('model.keras', 'labels.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0762c66f-889c-42cf-938f-72cb275b84d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 91ms/step\n",
      "Predicted class: tenor\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    classifier = VoiceClassifier(data_dir='dataset')\n",
    "    # voice_classifier.train_model()\n",
    "    classifier.preprocess_data()\n",
    "    classifier.model = load_model('model.keras')\n",
    "    audio_file = 'tenor_pavarotti.wav'\n",
    "    classifier.predict_audio(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "037d3519-6360-45a3-bf59-cdec4d5973cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 132ms/step\n",
      "Predicted Class Index:  3\n",
      "Labels:  ['alto', 'bass', 'soprano', 'tenor']\n",
      "Predicted class: tenor\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier = VoiceClassifier(data_dir='dataset')\n",
    "# voice_classifier.train_model()\n",
    "classifier.load_model('model.keras', 'labels.json')\n",
    "audio_file = 'tenor_pavarotti.wav'\n",
    "classifier.predict_audio(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa44f21-987c-4bc9-a95b-714c87dd0bef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
